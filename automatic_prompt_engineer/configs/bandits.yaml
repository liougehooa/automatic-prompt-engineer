generation:
  num_gen_prompts: 10 # the number of gen prompts with different samples sent to the LLM for each prompt
  num_samples_per_gen_prompt: 6 # the number of few shots, input & output pairs sent to the LLM for each prompt
  system_prompt: 请指导GPT-4模型生成一系列高效的中文提示（prompt），根据任务描述和一些样例，用以指引语言模型自动地生成和挑选出最佳的执行命令。\n1. 这些提示需要能够适用于各类自然语言处理任务。确保这些提示能够辅助模型准确理解和执行复杂任务，并在保证输出的真实性和丰富信息量方面有所帮助。\n2. 此外，这些提示也应当能够增强模型在少样本学习（few-shot learning）情境下的表现。\n3. 请逐步进行推理，确保我们能得出正确的答案。\n4. 您的提示中不能包含关于样例的输入和输出具体信息。\n5. 您的提示中不能包含仇恨，暴力，违法，自残，色情等有害信息。\n基于这些需求，为GPT-4模型制定一组中文提示（prompt）。
  user_template: 以下是一些测试样例：\n[DEMOS]\n\n以下是样例的任务描述： [TASK_DESC]\n\n请生成您的中文提示，仅此而已。发挥创意。
  demo_template: 输入：\n[INPUT]\n输出：\n[OUTPUT]\n
  batch_size: 2 # the maximum batch size used for prompt generation
  model:
    name: AOAI # the name of the model used for prompt generation
    azure_openai_endpoint: https://xingdongfang-workshop.openai.azure.com/
    api_version: 2024-06-01
    gpt_config: # the configuration of the GPT model used for prompt generation (these are fed directly to the openai function)
      n: 3 # the number of choices generated by LLM for each prompt
      model: 4o
      temperature: 0.9
      max_tokens: 1000
      top_p: 0.9
      frequency_penalty: 0.0
      presence_penalty: 0.0
evaluation:
  method: bandits # the evaluation method used for prompt evaluation
  rounds: 5 # the number of rounds of evaluation
  warm_rounds: 3 # the number of rounds of evaluation
  # stop_score: 100 # the number of rounds of evaluation
  num_prompts_per_round: 7 # the number of prompts with highest UCB scores to select for next round of evaluation
  bandit_method: ucb # the bandit method used for prompt evaluation (only supports ucb)
  bandit_config:
    c: 1.0 ## alogritm parameter for UCB, sqart(2)
  base_eval_method: elo # the base evaluation method used for prompt evaluation (replace this string with the evaluation function you want to use if you make a custom evaluation function)
  base_eval_config:
    ranking_system_prompt: 你的工作是对给定任务的输入生成的两个输出的质量进行排名。你将获得给定任务的描述、给定任务的输入和两个生成的输出。\n请按质量顺序对生成的输出进行排名。如果输出A更好，回答'A'。如果输出B更好，回答'B'。\n记住，要被认为是'更好'，一个输出不仅要好，还必须明显优于另一个。\n同时，请记住，你是一个非常严格的评论家。只有当一个输出真正比另一个更让你印象深刻时，才将其排名为更好。\n回答你的选项就够了，仅此而已。在你的判断中要公平无偏。
    user_template: 任务：\n[TASK]\n输入：\n[INPUT]\n输出 A：\n[GENERATION_A]\n输出 B：\n[GENERATION_b]\n
    num_samples: 8 # a prompt is evaluated with data of randonly selected num_samples (during each round of evaluation)
    # num_few_shot: 3 # the number of samples used for few-shot evaluation (only used if [full_DEMO] is present in the eval_template)
    elo_k: 32
    batch_size: 3
    gen_model:
      name: AOAI
      azure_openai_endpoint: https://xingdongfang-workshop.openai.azure.com/
      api_version: 2024-06-01
      gpt_config:
        model: 4o
        temperature: 0.7
        max_tokens: 50
        top_p: 1.0
        frequency_penalty: 0.0
        presence_penalty: 0.0
    score_model:
      name: AOAI
      azure_openai_endpoint: https://xingdongfang-workshop.openai.azure.com/
      api_version: 2024-06-01
      gpt_config:
        model: 4o-another
        temperature: 0.5
        max_tokens: 1
        top_p: 1.0
        frequency_penalty: 0.0
        presence_penalty: 0.0
demo:
  batch_size: 2
  model:
    name: AOAI
    azure_openai_endpoint: https://xingdongfang-workshop.openai.azure.com/
    api_version: 2024-06-01
    gpt_config:
      model: 4o
      temperature: 0.7
      max_tokens: 4000
      top_p: 1.0
      frequency_penalty: 0.0
      presence_penalty: 0.0
